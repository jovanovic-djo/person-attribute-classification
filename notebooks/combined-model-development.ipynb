{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import layers as L\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23700</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.49803922, 0.39215687, 0.36862746, 0.3176470...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23701</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.09019608, 0.10980392, 0.1254902, 0.13725491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23702</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.23137255, 0.19607843, 0.14509805, 0.1568627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23703</th>\n",
       "      <td>99</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1764706, 0.42352942, 0.47058824, 0.6117647,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23704</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.6117647, 0.6313726, 0.627451, 0.64705884, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  ethnicity  gender  \\\n",
       "23700   99          0       1   \n",
       "23701   99          1       1   \n",
       "23702   99          2       1   \n",
       "23703   99          2       1   \n",
       "23704   99          0       1   \n",
       "\n",
       "                                                  pixels  \n",
       "23700  [0.49803922, 0.39215687, 0.36862746, 0.3176470...  \n",
       "23701  [0.09019608, 0.10980392, 0.1254902, 0.13725491...  \n",
       "23702  [0.23137255, 0.19607843, 0.14509805, 0.1568627...  \n",
       "23703  [0.1764706, 0.42352942, 0.47058824, 0.6117647,...  \n",
       "23704  [0.6117647, 0.6313726, 0.627451, 0.64705884, 0...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/people_data.csv\")\n",
    "df = df.drop(\"img_name\",axis=1)\n",
    "df[\"pixels\"] = df[\"pixels\"].apply(lambda x: np.array(x.split(),dtype=\"float32\"))\n",
    "df[\"pixels\"] = df[\"pixels\"] / 255\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23705, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros(shape=(23705, 2304))\n",
    "x = x.reshape(-1, 48, 48, 1)\n",
    "print(x.shape)  #Input: (batch_size, height, width, channels) e.g., (batch_size, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1] [2 2 2 ... 2 2 0] [ 1  1  1 ... 99 99 99]\n"
     ]
    }
   ],
   "source": [
    "y_gender = df['gender'].values\n",
    "y_ethnicity = df['ethnicity'].values\n",
    "y_age = df['age'].values\n",
    "\n",
    "print(y_gender, y_ethnicity, y_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_temp, y_gender_train, y_gender_temp, y_ethnicity_train, y_ethnicity_temp, y_age_train, y_age_temp = train_test_split(\n",
    "    x, y_gender, y_ethnicity, y_age, \n",
    "    test_size=0.2, \n",
    "    random_state=20,\n",
    "    shuffle=True,\n",
    "    #stratify=y_ethnicity\n",
    ")\n",
    "\n",
    "x_val, x_test, y_gender_val, y_gender_test, y_ethnicity_val, y_ethnicity_test, y_age_val, y_age_test = train_test_split(\n",
    "    x_temp, y_gender_temp, y_ethnicity_temp, y_age_temp, \n",
    "    test_size=0.25, \n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    #stratify=y_ethnicity_temp\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "\n",
    "# n_bins = 10\n",
    "# est = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='uniform')\n",
    "# y_age_binned = est.fit_transform(y_age.reshape(-1, 1)).astype(int).flatten()\n",
    "\n",
    "# y_combined = np.vstack((y_gender, y_ethnicity, y_age_binned)).T\n",
    "\n",
    "# msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# for train_idx, temp_idx in msss.split(x, y_combined):\n",
    "#     x_train, x_temp = x[train_idx], x[temp_idx]\n",
    "#     y_gender_train, y_gender_temp = y_gender[train_idx], y_gender[temp_idx]\n",
    "#     y_ethnicity_train, y_ethnicity_temp = y_ethnicity[train_idx], y_ethnicity[temp_idx]\n",
    "#     y_age_train, y_age_temp = y_age[train_idx], y_age[temp_idx]\n",
    "#     y_age_binned_train, y_age_binned_temp = y_age_binned[train_idx], y_age_binned[temp_idx]\n",
    "\n",
    "# msss_val_test = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "# for val_idx, test_idx in msss_val_test.split(x_temp, y_combined[temp_idx]):\n",
    "#     x_val, x_test = x_temp[val_idx], x_temp[test_idx]\n",
    "#     y_gender_val, y_gender_test = y_gender_temp[val_idx], y_gender_temp[test_idx]\n",
    "#     y_ethnicity_val, y_ethnicity_test = y_ethnicity_temp[val_idx], y_ethnicity_temp[test_idx]\n",
    "#     y_age_val, y_age_test = y_age_temp[val_idx], y_age_temp[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_val = x_val.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=[1, 40],\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    ")\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "age_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "y_age_train_scaled = age_scaler.fit_transform(y_age_train.reshape(-1, 1))\n",
    "y_age_val_scaled = age_scaler.transform(y_age_val.reshape(-1, 1))\n",
    "y_age_test_scaled = age_scaler.transform(y_age_test.reshape(-1, 1))\n",
    "\n",
    "\n",
    "y_train = {\n",
    "    'gender': y_gender_train,\n",
    "    'ethnicity': y_ethnicity_train,\n",
    "    'age': y_age_train_scaled\n",
    "}\n",
    "\n",
    "y_val = {\n",
    "    'gender': y_gender_val,\n",
    "    'ethnicity': y_ethnicity_val,\n",
    "    'age': y_age_val_scaled\n",
    "}\n",
    "\n",
    "y_test = {\n",
    "    'gender': y_gender_test,\n",
    "    'ethnicity': y_ethnicity_test,\n",
    "    'age': y_age_test_scaled\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    x_train,\n",
    "    {\n",
    "        'gender': y_train['gender'],\n",
    "        'ethnicity': y_train['ethnicity'],\n",
    "        'age': y_train['age']\n",
    "    }\n",
    "))\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    x_val,\n",
    "    {\n",
    "        'gender': y_val['gender'],\n",
    "        'ethnicity': y_val['ethnicity'],\n",
    "        'age': y_val['age']\n",
    "    }\n",
    "))\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    x_test,\n",
    "    {\n",
    "        'gender': y_test['gender'],\n",
    "        'ethnicity': y_test['ethnicity'],\n",
    "        'age': y_test['age']\n",
    "    }\n",
    "))\n",
    "\n",
    "# Batch and prefetch\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024, seed=42).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_layers(input):\n",
    "    inputs = Input(shape=(48, 48, 1))\n",
    "    x = inputs\n",
    "    x = Conv2D(16, (3, 3), padding=\"same\")(input)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(5)(x)\n",
    "    x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ethnicity_branch(input):\n",
    "        x = build_layers(input)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(5)(x)\n",
    "        x = Activation(\"softmax\", name=\"race_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_age_branch(input):\n",
    "        x = build_layers(input)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(1)(x)\n",
    "        x = Activation(\"linear\", name=\"age_output\")(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def build_gender_branch(input):\n",
    "        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(input)\n",
    "        x = build_layers(input)\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(128)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = Dense(2)(x)\n",
    "        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "assemble_model() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[153], line 15\u001b[0m\n\u001b[0;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m Model(\n\u001b[0;32m      8\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m      9\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m [age_branch, race_branch, gender_branch],\n\u001b[0;32m     10\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mface_net\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m         )\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 15\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43massemble_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: assemble_model() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "def assemble_model(height, width):\n",
    "    input_shape = (height, width, 3)\n",
    "    inputs = Input(shape=input_shape)\n",
    "    age_branch = build_age_branch(inputs)\n",
    "    race_branch = build_ethnicity_branch(inputs)\n",
    "    gender_branch = build_gender_branch(inputs)\n",
    "    model = Model(\n",
    "        inputs=inputs,\n",
    "        outputs = [age_branch, race_branch, gender_branch],\n",
    "        name=\"face_net\"\n",
    "        )\n",
    "    return model\n",
    "\n",
    "    \n",
    "model = assemble_model(48, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early Stopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    # restore_best_weights=True,\n",
    "    min_delta=0.0005,\n",
    "    verbose=2, \n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "# Reduce Learning Rate on Plateau\n",
    "# lr_reduce = ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "#     factor=0.1,\n",
    "#     patience=3,\n",
    "#     verbose=2,\n",
    "#     min_lr=1e-6,\n",
    "#     mode=\"auto\",\n",
    "#     min_delta=0.0001,\n",
    "#     cooldown=0\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - age_loss: 3.7915 - age_mae: 0.2484 - age_mse: 0.0964 - ethnicity_accuracy: 0.2871 - ethnicity_loss: 1.5354 - gender_accuracy: 0.5104 - gender_auc: 0.4943 - gender_loss: 0.2055 - loss: 5.5325 - val_age_loss: 0.7303 - val_age_mae: 0.1577 - val_age_mse: 0.0352 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4623 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1404 - val_loss: 2.3218\n",
      "Epoch 2/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - age_loss: 0.7082 - age_mae: 0.1740 - age_mse: 0.0419 - ethnicity_accuracy: 0.4257 - ethnicity_loss: 1.4494 - gender_accuracy: 0.5271 - gender_auc: 0.4935 - gender_loss: 0.1385 - loss: 2.2962 - val_age_loss: 0.6971 - val_age_mae: 0.2084 - val_age_mse: 0.0577 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4582 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1298 - val_loss: 2.2720\n",
      "Epoch 3/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 46ms/step - age_loss: 0.6937 - age_mae: 0.2125 - age_mse: 0.0600 - ethnicity_accuracy: 0.4269 - ethnicity_loss: 1.4448 - gender_accuracy: 0.5255 - gender_auc: 0.5023 - gender_loss: 0.1326 - loss: 2.2711 - val_age_loss: 0.6940 - val_age_mae: 0.2248 - val_age_mse: 0.0663 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4578 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1289 - val_loss: 2.2676\n",
      "Epoch 4/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - age_loss: 0.6922 - age_mae: 0.2239 - age_mse: 0.0659 - ethnicity_accuracy: 0.4268 - ethnicity_loss: 1.4441 - gender_accuracy: 0.5247 - gender_auc: 0.4916 - gender_loss: 0.1321 - loss: 2.2684 - val_age_loss: 0.6935 - val_age_mae: 0.2295 - val_age_mse: 0.0688 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4577 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1288 - val_loss: 2.2671\n",
      "Epoch 5/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - age_loss: 0.6927 - age_mae: 0.2275 - age_mse: 0.0678 - ethnicity_accuracy: 0.4252 - ethnicity_loss: 1.4469 - gender_accuracy: 0.5268 - gender_auc: 0.4984 - gender_loss: 0.1316 - loss: 2.2713 - val_age_loss: 0.6934 - val_age_mae: 0.2307 - val_age_mse: 0.0695 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4577 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1289 - val_loss: 2.2670\n",
      "Epoch 6/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 57ms/step - age_loss: 0.6923 - age_mae: 0.2264 - age_mse: 0.0673 - ethnicity_accuracy: 0.4286 - ethnicity_loss: 1.4435 - gender_accuracy: 0.5274 - gender_auc: 0.4956 - gender_loss: 0.1319 - loss: 2.2677 - val_age_loss: 0.6935 - val_age_mae: 0.2296 - val_age_mse: 0.0689 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4576 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1288 - val_loss: 2.2671\n",
      "Epoch 7/30\n",
      "\u001b[1m297/297\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 54ms/step - age_loss: 0.6919 - age_mae: 0.2261 - age_mse: 0.0672 - ethnicity_accuracy: 0.4257 - ethnicity_loss: 1.4458 - gender_accuracy: 0.5269 - gender_auc: 0.5002 - gender_loss: 0.1321 - loss: 2.2698 - val_age_loss: 0.6936 - val_age_mae: 0.2284 - val_age_mse: 0.0682 - val_ethnicity_accuracy: 0.4253 - val_ethnicity_loss: 1.4576 - val_gender_accuracy: 0.5072 - val_gender_auc: 0.5000 - val_gender_loss: 0.1288 - val_loss: 2.2672\n",
      "Epoch 7: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss={\n",
    "        'gender': 'binary_crossentropy',\n",
    "        'ethnicity': 'sparse_categorical_crossentropy',\n",
    "        'age': 'mean_absolute_error'\n",
    "    },\n",
    "    metrics={\n",
    "        'gender': ['accuracy', tf.keras.metrics.AUC(name='auc')],\n",
    "        'ethnicity': ['accuracy'],\n",
    "        'age': ['mae', 'mse']\n",
    "    },\n",
    "    loss_weights={\n",
    "        'gender': 1.0,\n",
    "        'ethnicity': 1.0,\n",
    "        'age': 1.0\n",
    "    }\n",
    ")\n",
    "\n",
    "# Define the number of epochs\n",
    "EPOCHS = 30\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stop] #lr_reduce\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('../models/combined_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
