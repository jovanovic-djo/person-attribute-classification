{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import setuptools.dist\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from keras import layers as L\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  ethnicity  gender                        img_name  \\\n",
      "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
      "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
      "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
      "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
      "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
      "\n",
      "                                              pixels  \n",
      "0  129 128 128 126 127 130 133 135 139 142 145 14...  \n",
      "1  164 74 111 168 169 171 175 182 184 188 193 199...  \n",
      "2  67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
      "3  193 197 198 200 199 200 202 203 204 205 208 21...  \n",
      "4  202 205 209 210 209 209 210 211 212 214 218 21...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/people_data.csv\")\n",
    "print(df.head())\n",
    "df = df.drop(\"img_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pixels\"] = df[\"pixels\"].apply(lambda x: np.array(x.split(),dtype=\"float32\"))\n",
    "df[\"pixels\"] = df[\"pixels\"] / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros(shape=(23705,2304))\n",
    "\n",
    "for indexing in range(len(df[\"pixels\"])):\n",
    "    x_train[indexing] = df[\"pixels\"][indexing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1,48,48,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_train\n",
    "y = df.iloc[:, :-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, train_size=0.8, random_state=35, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    patience=5,\n",
    "    mode=\"min\"\n",
    "    )\n",
    "\n",
    "# checkpoint_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     monitor=\"val_accuracy\",\n",
    "#     save_best_only=True,\n",
    "#     save_weights_only=False,\n",
    "#     filepath=\"./.keras\"\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPILE_OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "COMPILE_LOSS = \"msle\"\n",
    "COMPILE_METRICS = [\"accuracy\"]\n",
    "INPUT_SHAPE = (x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
    "OUTPUT_CLASS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(L.Input(shape=INPUT_SHAPE))\n",
    "model.add(L.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(L.Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(L.Dropout(0.3))\n",
    "model.add(L.MaxPooling2D((2,2)))\n",
    "model.add(L.BatchNormalization())\n",
    "\n",
    "model.add(L.Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(L.Dropout(0.3))\n",
    "model.add(L.MaxPooling2D((2,2)))\n",
    "model.add(L.BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(L.Flatten())\n",
    "model.add(L.Dense(128,activation=\"relu\"))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(64,activation=\"relu\"))\n",
    "model.add(L.BatchNormalization())\n",
    "model.add(L.Dropout(0.5))\n",
    "model.add(L.Dense(OUTPUT_CLASS,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=COMPILE_OPTIMIZER,loss=COMPILE_LOSS,metrics=COMPILE_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.4946 - loss: 3.3666 - val_accuracy: 0.9515 - val_loss: 2.8298\n",
      "Epoch 2/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7972 - loss: 3.0228 - val_accuracy: 0.9580 - val_loss: 2.8122\n",
      "Epoch 3/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8560 - loss: 2.9241 - val_accuracy: 0.9547 - val_loss: 2.8088\n",
      "Epoch 4/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8994 - loss: 2.8649 - val_accuracy: 0.9584 - val_loss: 2.8067\n",
      "Epoch 5/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - accuracy: 0.9453 - loss: 2.8368 - val_accuracy: 0.9612 - val_loss: 2.8059\n",
      "Epoch 6/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - accuracy: 0.9525 - loss: 2.8261 - val_accuracy: 0.9608 - val_loss: 2.8060\n",
      "Epoch 7/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 31ms/step - accuracy: 0.9564 - loss: 2.8113 - val_accuracy: 0.9610 - val_loss: 2.8059\n",
      "Epoch 8/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - accuracy: 0.9546 - loss: 2.8238 - val_accuracy: 0.9603 - val_loss: 2.8058\n",
      "Epoch 9/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - accuracy: 0.9579 - loss: 2.8064 - val_accuracy: 0.9606 - val_loss: 2.8059\n",
      "Epoch 10/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16240s\u001b[0m 10s/step - accuracy: 0.9585 - loss: 2.7922 - val_accuracy: 0.9608 - val_loss: 2.8056\n",
      "Epoch 11/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - accuracy: 0.9582 - loss: 2.8129 - val_accuracy: 0.9606 - val_loss: 2.8059\n",
      "Epoch 12/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - accuracy: 0.9583 - loss: 2.8155 - val_accuracy: 0.9606 - val_loss: 2.8058\n",
      "Epoch 13/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 24ms/step - accuracy: 0.9606 - loss: 2.8170 - val_accuracy: 0.9603 - val_loss: 2.8058\n",
      "Epoch 14/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9599 - loss: 2.8145 - val_accuracy: 0.9601 - val_loss: 2.8058\n",
      "Epoch 15/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9583 - loss: 2.8170 - val_accuracy: 0.9614 - val_loss: 2.8050\n",
      "Epoch 16/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 26ms/step - accuracy: 0.9607 - loss: 2.8128 - val_accuracy: 0.9616 - val_loss: 2.8041\n",
      "Epoch 17/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9621 - loss: 2.8237 - val_accuracy: 0.9610 - val_loss: 2.8046\n",
      "Epoch 18/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 24ms/step - accuracy: 0.9632 - loss: 2.8052 - val_accuracy: 0.9603 - val_loss: 2.8054\n",
      "Epoch 19/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.9614 - loss: 2.8144 - val_accuracy: 0.9610 - val_loss: 2.8044\n",
      "Epoch 20/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - accuracy: 0.9637 - loss: 2.8103 - val_accuracy: 0.9608 - val_loss: 2.8057\n",
      "Epoch 21/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9671 - loss: 2.8230 - val_accuracy: 0.9627 - val_loss: 2.8037\n",
      "Epoch 22/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - accuracy: 0.9664 - loss: 2.8247 - val_accuracy: 0.9603 - val_loss: 2.8053\n",
      "Epoch 23/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 27ms/step - accuracy: 0.9639 - loss: 2.8057 - val_accuracy: 0.9618 - val_loss: 2.8042\n",
      "Epoch 24/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9636 - loss: 2.8065 - val_accuracy: 0.9614 - val_loss: 2.8040\n",
      "Epoch 25/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - accuracy: 0.9647 - loss: 2.8147 - val_accuracy: 0.9620 - val_loss: 2.8037\n",
      "Epoch 26/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 26ms/step - accuracy: 0.9643 - loss: 2.7958 - val_accuracy: 0.9614 - val_loss: 2.8031\n",
      "Epoch 27/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - accuracy: 0.9659 - loss: 2.8038 - val_accuracy: 0.9614 - val_loss: 2.8038\n",
      "Epoch 28/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 33ms/step - accuracy: 0.9662 - loss: 2.8005 - val_accuracy: 0.9616 - val_loss: 2.8038\n",
      "Epoch 29/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.9706 - loss: 2.8084 - val_accuracy: 0.9629 - val_loss: 2.8027\n",
      "Epoch 30/30\n",
      "\u001b[1m1581/1581\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - accuracy: 0.9673 - loss: 2.8164 - val_accuracy: 0.9631 - val_loss: 2.8026\n"
     ]
    }
   ],
   "source": [
    "path = '../models/combined_model.h5'\n",
    "\n",
    "cnn_model = model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_data=(\n",
    "        x_test, \n",
    "        y_test),\n",
    "    callbacks=[early_stopper], # checkpoint_model\n",
    "    batch_size=12,\n",
    "    epochs=30\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
